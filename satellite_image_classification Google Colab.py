# -*- coding: utf-8 -*-
"""Satellite Image Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ooYDi4s7UfpiHOPNd6fgxE7Fwbk8kH4
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
mahmoudreda55_satellite_image_classification_path = kagglehub.dataset_download('mahmoudreda55/satellite-image-classification')

print('Data source import complete.')

import os
import cv2
import tensorflow
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, Xception, InceptionResNetV2, ResNet50V2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix

data_dir = '/kaggle/input/satellite-image-classification/data'

categories  = ['cloudy', 'desert', 'green_area', 'water']
data = []
data_labels = []

for categorie in categories :
    folder_path = os.path.join(data_dir, categorie)
    image_paths = os.listdir(folder_path)
    data.extend([os.path.join(folder_path, image_path) for image_path in image_paths])
    data_labels.extend([categorie] * len(image_paths))
data = pd.DataFrame({'Image_Path' : data, 'labels' : data_labels})
data

labels = ['cloudy', 'desert', 'green_area', 'water']

for label in labels:
    sample_images = data[data['labels'] == label]['Image_Path'].reset_index(drop=True)[:5]

    print(f"Displaying Some Sample images of '{label}' categorie : ")
    plt.figure(figsize=(20, 8))
    # Displaying Some Sample images in BGR
    for i in range(len(sample_images)):
        plt.subplot(2, 5, i + 1)
        img = cv2.imread(sample_images[i])
        plt.imshow(img)
        plt.title(label, fontsize=9)
        plt.axis('off')
    plt.show()
    # Displaying Some Sample images in RGB
    plt.figure(figsize=(20, 8))
    for i in range(len(sample_images)):
        plt.subplot(2, 5, i + 1 + 5)
        img = cv2.imread(sample_images[i])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.imshow(img)
        plt.title(label, fontsize=9)
        plt.axis('off')

    plt.show()

data['labels'].value_counts().plot(kind = 'bar', color = ['red', 'blue', 'black', 'yellow'])
plt.title('Number of samples in every categorie : ', fontsize = 15)
plt.xlabel('Categories')
plt.ylabel('No.of samples')
plt.grid(axis='y', linestyle='--', alpha=0.7)

datagen = ImageDataGenerator(
    rescale = 1./255,
    validation_split = 0.25,
    rotation_range = 40,
    width_shift_range = 0.2,
    height_shift_range = 0.3,
    horizontal_flip = True,
    zoom_range = 0.2
)

# Training Data
train_data = datagen.flow_from_directory(
    data_dir,
    target_size=(75, 75),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Validation Data
val_data = datagen.flow_from_directory(
    data_dir,
    target_size=(75, 75),
    batch_size=1,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Test Data (Separate folder or another 10% of data)
test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for test data
test_data = test_datagen.flow_from_directory(
    data_dir,
    target_size=(75, 75),
    batch_size=10,
    class_mode='categorical',
    shuffle=True
)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_data.classes),
    y=train_data.classes
)
class_weights = dict(enumerate(class_weights))

vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(75, 75, 3))

# Freeze the layers of the base model
for layer in vgg_model.layers:
    layer.trainable = False

# Add custom layers
x = vgg_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Create the model
model1 = Model(inputs = vgg_model.input, outputs=predictions)

InceptionResNetV2_model = InceptionResNetV2(include_top=False, weights="imagenet", input_shape=(75, 75, 3))

# Freeze the layers of the base model
for layer in InceptionResNetV2_model.layers:
    layer.trainable = False

# Add custom layers
x = InceptionResNetV2_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Create the model
model2 = Model(inputs = InceptionResNetV2_model.input, outputs=predictions)

Xception_model = Xception(include_top=False, weights="imagenet", input_shape=(75,75,3))

# Freeze the layers of the base model
for layer in Xception_model.layers:
    layer.trainable = False

# Add custom layers
x = Xception_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Create the model
model3 = Model(inputs = Xception_model.input, outputs=predictions)

ResNet50V2_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(75,75,3))

# Freeze the layers of the base model
for layer in ResNet50V2_model.layers:
    layer.trainable = False

# Add custom layers
x = ResNet50V2_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Create the model
model4 = Model(inputs = ResNet50V2_model.input, outputs=predictions)

# Compile the model
model1.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy']
            )

model2.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy']
            )

model3.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy']
            )

model4.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy']
            )

# EarlyStoping the model
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)
# Learning Rate Decay
lrd = ReduceLROnPlateau(monitor = 'val_loss', patience = 5,verbose = 1,factor = 0.50, min_lr = 1e-10)

# Train the model1
mc1 = ModelCheckpoint('best_VGG16_Satellite_Image_Classification_Model.keras',monitor='val_loss', mode='min', save_best_only=True)
history = model1.fit(
    train_data,
    validation_data=val_data,
    epochs=25,
    class_weight=class_weights,
    callbacks=[es, mc1, lrd]
)

# Train the model
mc2 = ModelCheckpoint('best_InceptionResNetV2_Satellite_Image_Classification_Model.keras',monitor='val_loss', mode='min', save_best_only=True)
history = model2.fit(
    train_data,
    validation_data=val_data,
    epochs=25,
    class_weight=class_weights,
    callbacks=[es, mc2, lrd]
)

# Train the model
mc3 = ModelCheckpoint('best_Xception_Satellite_Image_Classification_Model.keras',monitor='val_loss', mode='min', save_best_only=True)
history = model3.fit(
    train_data,
    validation_data=val_data,
    epochs=15,
    class_weight=class_weights,
    callbacks=[es, mc3, lrd]
)

# Train the model
mc4 = ModelCheckpoint('best_ResNet50V2_Satellite_Image_Classification_Model.keras',monitor='val_loss', mode='min', save_best_only=True)
history = model4.fit(
    train_data,
    validation_data=val_data,
    epochs=15,
    class_weight=class_weights,
    callbacks=[es, mc4, lrd]
)

val_loss, val_accuracy = model1.evaluate(val_data)
print(f"Model1 Validation Loss: {val_loss}")
print(f"Model1 Validation Accuracy: {val_accuracy}")

val_loss, val_accuracy = model2.evaluate(val_data)
print(f"Model2 Validation Loss: {val_loss}")
print(f"Model2 Validation Accuracy: {val_accuracy}")

val_loss, val_accuracy = model3.evaluate(val_data)
print(f"Model3 Validation Loss: {val_loss}")
print(f"Model3 Validation Accuracy: {val_accuracy}")

val_loss, val_accuracy = model4.evaluate(val_data)
print(f"Model4 Validation Loss: {val_loss}")
print(f"Model4 Validation Accuracy: {val_accuracy}")

# Plotting the training and validation los

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plotting the training and validation accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

class_names = list(val_data.class_indices.keys())

# Get predictions for the validation data
val_predictions = model4.predict(val_data)
y_pred = np.argmax(val_predictions, axis=1)  # Predicted classes
y_true = val_data.classes  # True classes from the generator

print("\nTest Classification Report:")
print(classification_report(y_true, y_pred, target_names=list(test_data.class_indices.keys())))

# Generate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)

plt.title('Confusion Matrix - Validation Dataset')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Get class names from the generator
class_names = list(test_data.class_indices.keys())

num_rows = int(np.ceil(10 / 5))  # Calculate rows dynamically

# Set up the figure size
plt.figure(figsize=(20, 8))

# Extract 10 images and their labels from the test generator
test_images, test_labels = next(test_data)  # Fetch a single batch from test_data
test_images = test_images[:10]
test_labels = test_labels[:10]

# Loop through the samples for display
for i in range(10):
    # Preprocess the image for prediction
    img = test_images[i]  # Already preprocessed by ImageDataGenerator
    true_class = np.argmax(test_labels[i])  # Get the true label
    predicted_class = np.argmax(model4.predict(np.expand_dims(img, axis=0)), axis=-1)  # Predict class
    # Determine if the prediction is correct
    is_correct = true_class == predicted_class[0]
    # Set the color based on whether the prediction is correct
    title_color = 'green' if is_correct else 'red'
    # Display the image
    plt.subplot(num_rows, 5, i + 1)
    plt.imshow(img)  # Image is already scaled between 0 and 1
    plt.title(f"Actual: {class_names[true_class]}\nPredicted: {class_names[predicted_class[0]]}", fontsize = 20, color=title_color)
    plt.axis('off')

# Add a global title
plt.suptitle('Satellite Image Classification Predictions (10 Samples)', fontsize=20)
plt.tight_layout()
plt.subplots_adjust(top=0.85)  # Adjust spacing for the title
plt.show()